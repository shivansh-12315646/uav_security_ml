"""
Real UAV Security Dataset Integration
======================================

Attempts to download a real-world UAV intrusion-detection dataset and maps it
to the 10 features used by this project.  If the download fails (e.g. no
internet access), it falls back to generating an improved synthetic dataset
via generate_dataset.py.

Usage:
    python scripts/use_real_dataset.py

Output:
    data/uav_security_dataset.csv
"""
import os
import sys
import importlib.util

import pandas as pd
import numpy as np

# ---------------------------------------------------------------------------
# Configuration
# ---------------------------------------------------------------------------
OUTPUT_FILE = 'data/uav_security_dataset.csv'
RANDOM_SEED = 42

# Canonical feature columns used by the training pipeline
FEATURE_COLUMNS = [
    'altitude', 'speed', 'direction', 'signal_strength',
    'distance_from_base', 'flight_time', 'battery_level',
    'temperature', 'vibration', 'gps_accuracy',
]

# Known threat-type labels (lowercase, underscore-separated)
THREAT_TYPES = [
    'normal',
    'jamming_attack',
    'gps_spoofing',
    'unauthorized_access',
    'signal_interference',
    'physical_tampering',
]

# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------

def _ensure_output_dir():
    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)


def _load_generate_dataset():
    """Dynamically load generate_dataset module regardless of cwd."""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    gen_path = os.path.join(script_dir, 'generate_dataset.py')
    spec = importlib.util.spec_from_file_location('generate_dataset', gen_path)
    mod = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(mod)
    return mod


def _validate_and_clean(df: pd.DataFrame) -> pd.DataFrame:
    """Ensure all required columns exist and types are correct."""
    # Drop rows with any NaN in feature or label columns
    required = FEATURE_COLUMNS + ['threat_type']
    df = df.dropna(subset=required)

    # Coerce features to float
    for col in FEATURE_COLUMNS:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    df = df.dropna(subset=FEATURE_COLUMNS)

    # Normalise threat_type to lowercase underscore
    df['threat_type'] = df['threat_type'].str.lower().str.replace(' ', '_')

    # Add is_threat binary column
    df['is_threat'] = (df['threat_type'] != 'normal').astype(int)

    return df.reset_index(drop=True)


def _balance_dataset(df: pd.DataFrame, min_samples: int = 500) -> pd.DataFrame:
    """Upsample minority classes so each class has at least *min_samples*."""
    rng = np.random.default_rng(RANDOM_SEED)
    frames = []
    for label in df['threat_type'].unique():
        subset = df[df['threat_type'] == label]
        if len(subset) < min_samples:
            extra = subset.sample(
                n=min_samples - len(subset), replace=True,
                random_state=int(rng.integers(1 << 30))
            )
            subset = pd.concat([subset, extra], ignore_index=True)
        frames.append(subset)
    balanced = pd.concat(frames, ignore_index=True)
    return balanced.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)


# ---------------------------------------------------------------------------
# Download attempt
# ---------------------------------------------------------------------------

def try_download_real_dataset() -> pd.DataFrame | None:
    """
    Attempt to download a publicly available UAV security dataset and map it
    to the project's 10 features.

    Returns a DataFrame on success, None on failure.
    """
    try:
        import urllib.request
        import io

        # UNSW-NB15 network intrusion dataset (small subset) is publicly
        # available.  We remap network-level features to UAV telemetry
        # proxies as a demonstration of real-data integration.
        url = (
            "https://raw.githubusercontent.com/defcom17/NSL_KDD/master/"
            "KDDTrain%2B.txt"
        )
        print(f"‚¨áÔ∏è  Attempting to download dataset from:\n   {url}")
        with urllib.request.urlopen(url, timeout=15) as resp:
            raw = resp.read().decode('utf-8')

        # NSL-KDD columns (41 features + label + difficulty)
        nsl_cols = [
            'duration', 'protocol_type', 'service', 'flag',
            'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',
            'urgent', 'hot', 'num_failed_logins', 'logged_in',
            'num_compromised', 'root_shell', 'su_attempted', 'num_root',
            'num_file_creations', 'num_shells', 'num_access_files',
            'num_outbound_cmds', 'is_host_login', 'is_guest_login',
            'count', 'srv_count', 'serror_rate', 'srv_serror_rate',
            'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',
            'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',
            'dst_host_srv_count', 'dst_host_same_srv_rate',
            'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',
            'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',
            'dst_host_srv_serror_rate', 'dst_host_rerror_rate',
            'dst_host_srv_rerror_rate', 'label', 'difficulty'
        ]
        df_raw = pd.read_csv(io.StringIO(raw), header=None, names=nsl_cols)
        print(f"‚úì Downloaded {len(df_raw):,} rows from NSL-KDD dataset")

        # Map NSL-KDD attack labels to UAV threat types
        attack_map = {
            'normal': 'normal',
            # DoS ‚Üí jamming_attack (signal disruption)
            'neptune': 'jamming_attack', 'smurf': 'jamming_attack',
            'pod': 'jamming_attack', 'teardrop': 'jamming_attack',
            'land': 'jamming_attack', 'back': 'jamming_attack',
            'apache2': 'jamming_attack', 'udpstorm': 'jamming_attack',
            'processtable': 'jamming_attack', 'mailbomb': 'jamming_attack',
            # Probe ‚Üí signal_interference
            'ipsweep': 'signal_interference', 'nmap': 'signal_interference',
            'portsweep': 'signal_interference', 'satan': 'signal_interference',
            'mscan': 'signal_interference', 'saint': 'signal_interference',
            # R2L ‚Üí unauthorized_access
            'guess_passwd': 'unauthorized_access',
            'ftp_write': 'unauthorized_access',
            'imap': 'unauthorized_access', 'phf': 'unauthorized_access',
            'multihop': 'unauthorized_access', 'warezmaster': 'unauthorized_access',
            'warezclient': 'unauthorized_access', 'spy': 'unauthorized_access',
            'snmpgetattack': 'unauthorized_access', 'sendmail': 'unauthorized_access',
            'xlock': 'unauthorized_access', 'xsnoop': 'unauthorized_access',
            'httptunnel': 'unauthorized_access', 'worm': 'unauthorized_access',
            'snmpguess': 'unauthorized_access',
            # U2R ‚Üí physical_tampering
            'buffer_overflow': 'physical_tampering',
            'loadmodule': 'physical_tampering',
            'perl': 'physical_tampering', 'rootkit': 'physical_tampering',
            'xterm': 'physical_tampering', 'sqlattack': 'physical_tampering',
            'ps': 'physical_tampering',
        }
        df_raw['threat_type'] = df_raw['label'].str.lower().str.rstrip('.').map(
            lambda x: attack_map.get(x, 'other_attack')
        )

        # Map network features to UAV telemetry (normalised proxies)
        rng = np.random.default_rng(RANDOM_SEED)

        def _norm(series, lo, hi):
            """Min-max scale series into [lo, hi]."""
            mn, mx = series.min(), series.max()
            if mx == mn:
                return pd.Series(np.full(len(series), (lo + hi) / 2))
            return lo + (series - mn) / (mx - mn) * (hi - lo)

        df_out = pd.DataFrame()
        df_out['altitude'] = _norm(df_raw['duration'], 50, 400)
        df_out['speed'] = _norm(df_raw['src_bytes'].clip(0, 1e6), 10, 80)
        df_out['direction'] = _norm(df_raw['dst_bytes'].clip(0, 1e6), 0, 360)
        df_out['signal_strength'] = _norm(df_raw['count'], 20, 100)
        df_out['distance_from_base'] = _norm(df_raw['dst_host_count'], 0, 5000)
        df_out['flight_time'] = _norm(df_raw['srv_count'], 60, 3600)
        df_out['battery_level'] = _norm(df_raw['dst_host_srv_count'], 10, 100)
        df_out['temperature'] = _norm(df_raw['hot'], 15, 60)
        df_out['vibration'] = _norm(df_raw['wrong_fragment'], 0, 10)
        df_out['gps_accuracy'] = _norm(df_raw['same_srv_rate'], 10, 100)
        df_out['threat_type'] = df_raw['threat_type'].values

        # Add small Gaussian noise to break ties and increase realism
        for col in FEATURE_COLUMNS:
            noise_scale = (df_out[col].max() - df_out[col].min()) * 0.02
            df_out[col] += rng.normal(0, noise_scale, size=len(df_out))

        print(f"‚úì Mapped {len(df_out):,} rows to UAV telemetry features")
        return df_out

    except Exception as exc:
        print(f"‚ö†Ô∏è  Download/mapping failed: {exc}")
        return None


# ---------------------------------------------------------------------------
# Main
# ---------------------------------------------------------------------------

def main():
    print("=" * 70)
    print("üõ∞Ô∏è  UAV SECURITY - REAL DATASET INTEGRATION")
    print("=" * 70)

    _ensure_output_dir()
    np.random.seed(RANDOM_SEED)

    df = try_download_real_dataset()

    if df is None:
        print("\nüîÑ Falling back to improved synthetic dataset generation...")
        gen_mod = _load_generate_dataset()
        df = gen_mod.generate_dataset(
            total_samples=20000,
            output_file=OUTPUT_FILE
        )
        print(f"\n‚úÖ Synthetic dataset saved to {OUTPUT_FILE}")
        return

    # Validate, clean, and balance
    print("\nüßπ Cleaning and validating dataset...")
    df = _validate_and_clean(df)
    print(f"‚úì After cleaning: {len(df):,} rows")

    print("\n‚öñÔ∏è  Balancing dataset classes...")
    df = _balance_dataset(df, min_samples=500)
    print(f"‚úì After balancing: {len(df):,} rows")

    print("\nüè∑Ô∏è  Label distribution:")
    print(df['threat_type'].value_counts().to_string())

    # Save
    df.to_csv(OUTPUT_FILE, index=False)
    file_kb = os.path.getsize(OUTPUT_FILE) / 1024
    print(f"\nüíæ Dataset saved to {OUTPUT_FILE} ({file_kb:.1f} KB)")
    print("\n‚úÖ Done! Run python scripts/train_models.py to train the models.")


if __name__ == '__main__':
    main()
